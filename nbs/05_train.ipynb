{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp train\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train\n",
    "\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline](images/graphic10.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "from timm import create_model\n",
    "from fastai.vision.learner import _update_first_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using timm models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**>> With `fastai` version 2.6.0, `timm` models are integrated into `fastai` so you do not need to use this anymore**\n",
    "\n",
    "\n",
    "The following can be originally found in this [notebook](https://github.com/muellerzr/Practical-Deep-Learning-for-Coders-2.0/blob/master/Computer%20Vision/05_EfficientNet_and_Custom_Weights.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_timm_body(arch:str, pretrained=True, cut=None, n_in=3):\n",
    "    \"Creates a body from any model in the `timm` library.\"\n",
    "    model = create_model(arch, pretrained=pretrained, num_classes=0, global_pool='')\n",
    "    _update_first_layer(model, n_in, pretrained)\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n",
    "    if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut): return cut(model)\n",
    "    else: raise NamedError(\"cut must be either integer or function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_timm_model(arch:str, n_out, cut=None, pretrained=True, n_in=3, init=nn.init.kaiming_normal_, custom_head=None,\n",
    "                     concat_pool=True, **kwargs):\n",
    "    \"Create custom architecture using `arch`, `n_in` and `n_out` from the `timm` library\"\n",
    "    body = create_timm_body(arch, pretrained, None, n_in)\n",
    "    if custom_head is None:\n",
    "        nf = num_features_model(nn.Sequential(*body.children()))\n",
    "        head = create_head(nf, n_out, concat_pool=concat_pool, **kwargs)\n",
    "    else: head = custom_head\n",
    "    model = nn.Sequential(body, head)\n",
    "    if init is not None: apply_init(model[1], init)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def timm_learner(dls, arch:str, loss_func=None, pretrained=True, cut=None, splitter=None,\n",
    "                y_range=None, config=None, n_out=None, normalize=True, **kwargs):\n",
    "    \"Build a convnet style learner from `dls` and `arch` using the `timm` library\"\n",
    "    if config is None: config = {}\n",
    "    if n_out is None: n_out = get_c(dls)\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
    "    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')\n",
    "    model = create_timm_model(arch, n_out, default_split, pretrained, y_range=y_range, **config)\n",
    "    learn = Learner(dls, model, loss_func=loss_func, splitter=default_split, **kwargs)\n",
    "    if pretrained: learn.freeze()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EpochIteration(Callback):\n",
    "    \"Display Epoch and Iteration\"\n",
    "    def __init__(self, show_img=False):\n",
    "        self.show_img = show_img\n",
    "    def before_batch(self):\n",
    "        if self.training is not False:\n",
    "            b = f'Training: Epoch: {self.epoch} Iter: {self.iter} Loss:{self.loss}'\n",
    "        else:\n",
    "            b = f'Validation: Epoch: {self.epoch} Iter: {self.iter} Loss:{self.loss}'\n",
    "        \n",
    "        if self.show_img is not False: show_images(self.learn.xb[0], suptitle=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 02_explore.ipynb.\n",
      "Converted 03_preprocessing.ipynb.\n",
      "Converted 04_pipeline.ipynb.\n",
      "Converted 05_train.ipynb.\n",
      "Converted 06_examine.ipynb.\n",
      "Converted 10_wearable.ipynb.\n",
      "Converted 20_retinanet.ipynb.\n",
      "Converted 90_tutorial.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
