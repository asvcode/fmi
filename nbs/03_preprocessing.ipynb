{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp preprocessing\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre_processing\n",
    "\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![preprocessing](images/graphic8.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "from fastai.medical.imaging import *\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mask_and_save(df, source=None, show=None, window=dicom_windows.lungs, sigma:float=0.1, thresh:float=0.9, save=False, save_path=None):\n",
    "    image_list = []\n",
    "    for i in df.index:\n",
    "        file_path = f\"{source}/{df.iloc[i]['PatientID']}/{df.iloc[i]['InstanceNumber']}.dcm\"\n",
    "        file_name = df.iloc[i]['InstanceNumber']\n",
    "        dcm = dcmread(file_path)\n",
    "        wind = dcm.windowed(*window)\n",
    "        mask = dcm.mask_from_blur(window, sigma=sigma, thresh=thresh, remove_max=False)\n",
    "        bbs = mask2bbox(mask)\n",
    "        lo,hi = bbs\n",
    "        imh = wind[lo[0]:hi[0],lo[1]:hi[1]]\n",
    "        if save is not False:\n",
    "            save_image(imh, f'{save_path}/{file_name}.png')\n",
    "        else:\n",
    "            pass\n",
    "        image_list.append(imh)\n",
    "    if show is not None:\n",
    "        show_images(image_list[:10], nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"mask_and_save\" class=\"doc_header\"><code>mask_and_save</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>mask_and_save</code>(**`df`**, **`source`**=*`None`*, **`show`**=*`None`*, **`window`**=*`(1500, -600)`*, **`sigma`**:`float`=*`0.1`*, **`thresh`**:`float`=*`0.9`*, **`save`**=*`False`*, **`save_path`**=*`None`*)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(mask_and_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicom metadata dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change to allow selection of dicom window width and level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def updated_dict(self:DcmDataset, windows=[dicom_windows.lungs]):\n",
    "    pxdata = (0x7fe0,0x0010)\n",
    "    vals = [self[o] for o in self.keys() if o != pxdata]\n",
    "    its = [(v.keyword, v.value) for v in vals]\n",
    "    res = dict(its)\n",
    "    res['fname'] = self.filename\n",
    "    \n",
    "    stats = 'min', 'max', 'mean', 'std'\n",
    "    pxs = self.pixel_array\n",
    "    for f in stats: res['img_'+f] = getattr(pxs, f)()\n",
    "    res['img_pct_window'] = self.pct_in_window(*windows)\n",
    "    res['file_path'] = f'{self.PatientID}/{self.InstanceNumber}.dcm'\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _dcm2dict2(fn, windows, **kwargs): return fn.dcmread().updated_dict(windows, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(parallel)\n",
    "def _from_dicoms2(cls, fns, n_workers=0, **kwargs):\n",
    "    return pd.DataFrame(parallel(_dcm2dict2, fns, n_workers=n_workers, **kwargs))\n",
    "pd.DataFrame.from_dicoms2 = classmethod(_from_dicoms2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dicom convert 3channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dicom_convert_3channel(fn:(Path,str), save_dir:(str), win1=dicom_windows.lungs, \\\n",
    "                           win2=dicom_windows.liver, win3=dicom_windows.brain):\n",
    "    \"Split a dicom image into 3 windows with each window per channel and saved as jpg\"\n",
    "    data = dcmread(fn)\n",
    "    file_name = str(fn); name = file_name.split('\\\\')[-1].split('.')[0]\n",
    "        \n",
    "    chan_one = np.expand_dims(data.windowed(*win1), axis=2)\n",
    "    chan_two = np.expand_dims(data.windowed(*win2), axis=2)\n",
    "    chan_three = np.expand_dims(data.windowed(*(win3)), axis=2)\n",
    "    image = np.concatenate([chan_one, chan_two, chan_three], axis=2)\n",
    "    ten_image = TensorImage(image).permute(2,0,1)\n",
    "    save_image(ten_image, f'{save_dir}/{name}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"dicom_convert_3channel\" class=\"doc_header\"><code>dicom_convert_3channel</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>dicom_convert_3channel</code>(**`fn`**:`Path'>, <class 'str'>)`, **`save_dir`**:`str`, **`win1`**=*`(1500, -600)`*, **`win2`**=*`(150, 30)`*, **`win3`**=*`(80, 40)`*)\n",
       "\n",
       "Split a dicom image into 3 windows with each window per channel and saved as jpg"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(dicom_convert_3channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicom Splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open dicom splitter tutorial in Kaggle\n",
    "\n",
    "[<img src=\"images/kaggle.PNG\" width=\"80\" align='left'/>](https://www.kaggle.com/avirdee/dicom-splitter-tutorial/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dicomsplit(valid_pct=0.2, seed=None, **kwargs):\n",
    "    \"Splits `items` between train/val with `valid_pct`\"\n",
    "    \"and checks if identical patient IDs exist in both the train and valid sets\"\n",
    "    def _inner(o, **kwargs):\n",
    "        train_list = []; valid_list = []\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        rand_idx = L(int(i) for i in torch.randperm(len(o)))\n",
    "        cut = int(valid_pct * len(o))\n",
    "        trn = rand_idx[cut:]; trn_p = o[rand_idx[cut:]]\n",
    "        val = rand_idx[:cut]; val_p = o[rand_idx[:cut]]\n",
    "        train_patient = []; train_images = []\n",
    "        for i, tfile in enumerate(trn_p):\n",
    "            file = dcmread(tfile)\n",
    "            tpat = file.PatientID\n",
    "            train_patient.append(tpat)\n",
    "            file_array = dcmread(tfile).pixel_array\n",
    "            train_images.append(file_array)\n",
    "        val_patient = []; val_images = []\n",
    "        for i, vfile in enumerate(val_p):\n",
    "            file2 = dcmread(vfile)\n",
    "            vpat = file2.PatientID\n",
    "            val_patient.append(vpat)\n",
    "            val_array = dcmread(vfile).pixel_array\n",
    "            val_images.append(val_array)\n",
    "    \n",
    "        print(rand_idx)\n",
    "        print(f'Train: {trn}, {train_patient}')\n",
    "        show_images(train_images[:20])\n",
    "        print(f'Val: {val}, {val_patient}')\n",
    "        show_images(val_images[:20])\n",
    "        is_duplicate = set(train_patient) & set(val_patient)\n",
    "        print(f'Duplicate: {set(train_patient) & set(val_patient)}')\n",
    "        new_list = []\n",
    "        if bool(is_duplicate) is not False:\n",
    "            print('duplicate exists')\n",
    "            new_list = [elem for elem in train_patient if elem not in val_patient ]\n",
    "            print(f'New List: {new_list}')\n",
    "        else:\n",
    "            print('duplicate does NOT exist')\n",
    "            new_list = trn\n",
    "        return new_list, val\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"dicomsplit\" class=\"doc_header\"><code>dicomsplit</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>dicomsplit</code>(**`valid_pct`**=*`0.2`*, **`seed`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Splits `items` between train/val with `valid_pct`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(dicomsplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def check_duplicate(items, seed=5):\n",
    "    trn, val = dicomsplit(valid_pct=0.2, seed=seed)(items)\n",
    "    return trn, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dicom_splitter(items, valid_pct=0.2, seed=77):\n",
    "    trn, val = dicomsplit(valid_pct=valid_pct)(items)\n",
    "    valid_idx = val\n",
    "    def _inner(o):\n",
    "        train_idx = np.setdiff1d(np.array(range_of(o)), np.array(valid_idx))\n",
    "        print(f'train:{train_idx} val:{valid_idx}')\n",
    "        return L(train_idx, use_list=True), L(valid_idx, use_list=True)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"dicom_splitter\" class=\"doc_header\"><code>dicom_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>dicom_splitter</code>(**`items`**, **`valid_pct`**=*`0.2`*, **`seed`**=*`77`*)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(dicom_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open move files tutorial in Kaggle\n",
    "\n",
    "[<img src=\"images/kaggle.PNG\" width=\"80\" align='left'/>](https://www.kaggle.com/avirdee/pre-processing-tutorial/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def move_files(df, source, save_path):\n",
    "    \"helper to move files\"\n",
    "    for i in df.index:\n",
    "        #patient ID\n",
    "        patid = str(df.PatientID[i])\n",
    "        window = str(df.img_pct_window[i])\n",
    "        \n",
    "        #fname\n",
    "        filename = str(df.fname[i]).split('/')[-1]\n",
    "        img = filename.split('.')[0]\n",
    "        print(f'ID: {patid} window: {window} instance: {img}')\n",
    "        \n",
    "        folder_path = save_path + patid\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)   \n",
    "        img_file = Path(f'{source}/train/{patid}/{img}.dcm')\n",
    "        shutil.copy(img_file, folder_path, follow_symlinks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"move_files\" class=\"doc_header\"><code>move_files</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>move_files</code>(**`df`**, **`source`**, **`save_path`**)\n",
       "\n",
       "helper to move files"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(move_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 02_explore.ipynb.\n",
      "Converted 03_preprocessing.ipynb.\n",
      "Converted 04_pipeline.ipynb.\n",
      "Converted 05_train.ipynb.\n",
      "Converted 06_examine.ipynb.\n",
      "Converted 90_tutorial.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
